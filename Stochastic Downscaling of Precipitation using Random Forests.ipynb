{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stochastic Downscaling of Precipitation using Random Forests\n",
    "### Worked Example using RandomForest2 package\n",
    "\n",
    "#### Mikel N. Legasa, Rodrigo Manzanas and José Manuel Gutiérrez.\n",
    "\n",
    "This is the companion notebook for the R package [**RandomForest2**](https://github.com/MNLR/RandomForest2), created with the purpose of extending random forests to accomodate for more split functions and estimation approaches. The package requires a modified version of [**rpart**](https://cran.r-project.org/web/packages/rpart/index.html) that can be found [here](https://github.com/MNLR/rpart). We briefly explain how to use the package by means of several examples.\n",
    "\n",
    "This examples present the R code to reproduce the random forest models for the paper *Stochastic Downscaling of Precipitation using Random Forests*, submited to ---, in which we apply random forests to the problem of statistical downscaling of rainfall. We briefly explain how to build the models presented in the paper and use them to predict and generate new precipitation series.\n",
    "\n",
    "The reader can install both packages from Github by means of the package `devtools`, executing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "devtools::install_github(\"MNLR/rpart\")\n",
    "install.packages(c(\"progressr\", \"qmap\", \"fitdistrplus\"))\n",
    "devtools::install_github(\"MNLR/RandomForest2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We load `RandomForest2` and the example dataset included, `VALUE9`. This dataset contains rainfall series for 9 meteorological stations over Europe, along with their corresponding 17 large scale reanalysis predictors at the 4 nearest grid points. It corresponds to the subset of 9 meteorological stations described in the article *Stochastic Downscaling of Precipitation using Random Forests* (check the article for more information on the dataset). We use this dataset to describe the functionality of the package."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading required package: rpart\n",
      "\n",
      "Loading required package: progressr\n",
      "\n"
     ]
    }
   ],
   "source": [
    "library(RandomForest2)\n",
    "data(VALUE9)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is a list of 9 elements, each one corresponding to a meteorological station. The data for each station is already divided into a stratified 5-fold (each fold comprises the years F1 = 1979−1984, F2 = 1985−1990, F3 = 1991-1996, F4 = 1997-2002, F5 = 2003-2008).  `$train.y` and `$test.y` correspond to the predictands; and `$train.x` and `$test.x` are the predictors. For example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<caption>A matrix: 6 × 69 of type dbl</caption>\n",
       "<tbody>\n",
       "\t<tr><td> 5.4</td><td>100934.56</td><td>101076.31</td><td>101029.38</td><td>101127.6</td><td>0.9725891</td><td>-0.5552429</td><td> 3.362726</td><td>1.4769836</td><td>53970.78</td><td>⋯</td><td>0.0008774727</td><td>0.0007474154</td><td>0.001837683</td><td>0.001404357</td><td>0.002788675</td><td>0.002296162</td><td>0.003939099</td><td>0.003326243</td><td>0.004503078</td><td>0.004167265</td></tr>\n",
       "\t<tr><td> 3.0</td><td> 99861.81</td><td>100098.66</td><td> 99890.75</td><td>100026.2</td><td>4.0751587</td><td> 2.3417603</td><td> 6.654260</td><td>4.7987915</td><td>53126.36</td><td>⋯</td><td>0.0007746874</td><td>0.0008232652</td><td>0.002964854</td><td>0.003158688</td><td>0.002753138</td><td>0.002897739</td><td>0.004851500</td><td>0.004605810</td><td>0.004810254</td><td>0.004700223</td></tr>\n",
       "\t<tr><td> 5.0</td><td>100774.52</td><td>101000.39</td><td>101343.70</td><td>101556.2</td><td>1.7720581</td><td> 0.8526245</td><td> 3.237878</td><td>0.7207886</td><td>53762.79</td><td>⋯</td><td>0.0008526679</td><td>0.0009968218</td><td>0.002528636</td><td>0.002547173</td><td>0.002720682</td><td>0.002845912</td><td>0.004383934</td><td>0.003969920</td><td>0.004411114</td><td>0.003889335</td></tr>\n",
       "\t<tr><td>12.9</td><td>100790.47</td><td>100810.84</td><td>101059.16</td><td>101159.5</td><td>4.7946411</td><td> 4.9987427</td><td> 7.108118</td><td>5.1798950</td><td>54141.42</td><td>⋯</td><td>0.0013121588</td><td>0.0011717600</td><td>0.002218187</td><td>0.002100289</td><td>0.002669751</td><td>0.002809047</td><td>0.004955770</td><td>0.004400434</td><td>0.005563976</td><td>0.005303564</td></tr>\n",
       "\t<tr><td>11.0</td><td> 99843.41</td><td> 99968.94</td><td>100306.59</td><td>100510.2</td><td>8.2443481</td><td> 8.8000122</td><td> 9.919641</td><td>7.6437622</td><td>53829.54</td><td>⋯</td><td>0.0012456127</td><td>0.0012676665</td><td>0.003520003</td><td>0.003533235</td><td>0.004003754</td><td>0.004093757</td><td>0.006390568</td><td>0.006163236</td><td>0.006739852</td><td>0.006437775</td></tr>\n",
       "\t<tr><td> 1.0</td><td> 99936.30</td><td> 99915.36</td><td>100108.30</td><td>100281.5</td><td>7.5472656</td><td> 9.0443359</td><td>10.253320</td><td>8.7977539</td><td>53769.01</td><td>⋯</td><td>0.0014264237</td><td>0.0015940617</td><td>0.003558955</td><td>0.004082522</td><td>0.003949782</td><td>0.004051825</td><td>0.005973617</td><td>0.006448189</td><td>0.006836812</td><td>0.006869952</td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "A matrix: 6 × 69 of type dbl\n",
       "\\begin{tabular}{lllllllllllllllllllll}\n",
       "\t  5.4 & 100934.56 & 101076.31 & 101029.38 & 101127.6 & 0.9725891 & -0.5552429 &  3.362726 & 1.4769836 & 53970.78 & ⋯ & 0.0008774727 & 0.0007474154 & 0.001837683 & 0.001404357 & 0.002788675 & 0.002296162 & 0.003939099 & 0.003326243 & 0.004503078 & 0.004167265\\\\\n",
       "\t  3.0 &  99861.81 & 100098.66 &  99890.75 & 100026.2 & 4.0751587 &  2.3417603 &  6.654260 & 4.7987915 & 53126.36 & ⋯ & 0.0007746874 & 0.0008232652 & 0.002964854 & 0.003158688 & 0.002753138 & 0.002897739 & 0.004851500 & 0.004605810 & 0.004810254 & 0.004700223\\\\\n",
       "\t  5.0 & 100774.52 & 101000.39 & 101343.70 & 101556.2 & 1.7720581 &  0.8526245 &  3.237878 & 0.7207886 & 53762.79 & ⋯ & 0.0008526679 & 0.0009968218 & 0.002528636 & 0.002547173 & 0.002720682 & 0.002845912 & 0.004383934 & 0.003969920 & 0.004411114 & 0.003889335\\\\\n",
       "\t 12.9 & 100790.47 & 100810.84 & 101059.16 & 101159.5 & 4.7946411 &  4.9987427 &  7.108118 & 5.1798950 & 54141.42 & ⋯ & 0.0013121588 & 0.0011717600 & 0.002218187 & 0.002100289 & 0.002669751 & 0.002809047 & 0.004955770 & 0.004400434 & 0.005563976 & 0.005303564\\\\\n",
       "\t 11.0 &  99843.41 &  99968.94 & 100306.59 & 100510.2 & 8.2443481 &  8.8000122 &  9.919641 & 7.6437622 & 53829.54 & ⋯ & 0.0012456127 & 0.0012676665 & 0.003520003 & 0.003533235 & 0.004003754 & 0.004093757 & 0.006390568 & 0.006163236 & 0.006739852 & 0.006437775\\\\\n",
       "\t  1.0 &  99936.30 &  99915.36 & 100108.30 & 100281.5 & 7.5472656 &  9.0443359 & 10.253320 & 8.7977539 & 53769.01 & ⋯ & 0.0014264237 & 0.0015940617 & 0.003558955 & 0.004082522 & 0.003949782 & 0.004051825 & 0.005973617 & 0.006448189 & 0.006836812 & 0.006869952\\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "A matrix: 6 × 69 of type dbl\n",
       "\n",
       "|  5.4 | 100934.56 | 101076.31 | 101029.38 | 101127.6 | 0.9725891 | -0.5552429 |  3.362726 | 1.4769836 | 53970.78 | ⋯ | 0.0008774727 | 0.0007474154 | 0.001837683 | 0.001404357 | 0.002788675 | 0.002296162 | 0.003939099 | 0.003326243 | 0.004503078 | 0.004167265 |\n",
       "|  3.0 |  99861.81 | 100098.66 |  99890.75 | 100026.2 | 4.0751587 |  2.3417603 |  6.654260 | 4.7987915 | 53126.36 | ⋯ | 0.0007746874 | 0.0008232652 | 0.002964854 | 0.003158688 | 0.002753138 | 0.002897739 | 0.004851500 | 0.004605810 | 0.004810254 | 0.004700223 |\n",
       "|  5.0 | 100774.52 | 101000.39 | 101343.70 | 101556.2 | 1.7720581 |  0.8526245 |  3.237878 | 0.7207886 | 53762.79 | ⋯ | 0.0008526679 | 0.0009968218 | 0.002528636 | 0.002547173 | 0.002720682 | 0.002845912 | 0.004383934 | 0.003969920 | 0.004411114 | 0.003889335 |\n",
       "| 12.9 | 100790.47 | 100810.84 | 101059.16 | 101159.5 | 4.7946411 |  4.9987427 |  7.108118 | 5.1798950 | 54141.42 | ⋯ | 0.0013121588 | 0.0011717600 | 0.002218187 | 0.002100289 | 0.002669751 | 0.002809047 | 0.004955770 | 0.004400434 | 0.005563976 | 0.005303564 |\n",
       "| 11.0 |  99843.41 |  99968.94 | 100306.59 | 100510.2 | 8.2443481 |  8.8000122 |  9.919641 | 7.6437622 | 53829.54 | ⋯ | 0.0012456127 | 0.0012676665 | 0.003520003 | 0.003533235 | 0.004003754 | 0.004093757 | 0.006390568 | 0.006163236 | 0.006739852 | 0.006437775 |\n",
       "|  1.0 |  99936.30 |  99915.36 | 100108.30 | 100281.5 | 7.5472656 |  9.0443359 | 10.253320 | 8.7977539 | 53769.01 | ⋯ | 0.0014264237 | 0.0015940617 | 0.003558955 | 0.004082522 | 0.003949782 | 0.004051825 | 0.005973617 | 0.006448189 | 0.006836812 | 0.006869952 |\n",
       "\n"
      ],
      "text/plain": [
       "     [,1] [,2]      [,3]      [,4]      [,5]     [,6]      [,7]       [,8]     \n",
       "[1,]  5.4 100934.56 101076.31 101029.38 101127.6 0.9725891 -0.5552429  3.362726\n",
       "[2,]  3.0  99861.81 100098.66  99890.75 100026.2 4.0751587  2.3417603  6.654260\n",
       "[3,]  5.0 100774.52 101000.39 101343.70 101556.2 1.7720581  0.8526245  3.237878\n",
       "[4,] 12.9 100790.47 100810.84 101059.16 101159.5 4.7946411  4.9987427  7.108118\n",
       "[5,] 11.0  99843.41  99968.94 100306.59 100510.2 8.2443481  8.8000122  9.919641\n",
       "[6,]  1.0  99936.30  99915.36 100108.30 100281.5 7.5472656  9.0443359 10.253320\n",
       "     [,9]      [,10]    [,11] [,12]        [,13]        [,14]       [,15]      \n",
       "[1,] 1.4769836 53970.78 ⋯     0.0008774727 0.0007474154 0.001837683 0.001404357\n",
       "[2,] 4.7987915 53126.36 ⋯     0.0007746874 0.0008232652 0.002964854 0.003158688\n",
       "[3,] 0.7207886 53762.79 ⋯     0.0008526679 0.0009968218 0.002528636 0.002547173\n",
       "[4,] 5.1798950 54141.42 ⋯     0.0013121588 0.0011717600 0.002218187 0.002100289\n",
       "[5,] 7.6437622 53829.54 ⋯     0.0012456127 0.0012676665 0.003520003 0.003533235\n",
       "[6,] 8.7977539 53769.01 ⋯     0.0014264237 0.0015940617 0.003558955 0.004082522\n",
       "     [,16]       [,17]       [,18]       [,19]       [,20]       [,21]      \n",
       "[1,] 0.002788675 0.002296162 0.003939099 0.003326243 0.004503078 0.004167265\n",
       "[2,] 0.002753138 0.002897739 0.004851500 0.004605810 0.004810254 0.004700223\n",
       "[3,] 0.002720682 0.002845912 0.004383934 0.003969920 0.004411114 0.003889335\n",
       "[4,] 0.002669751 0.002809047 0.004955770 0.004400434 0.005563976 0.005303564\n",
       "[5,] 0.004003754 0.004093757 0.006390568 0.006163236 0.006739852 0.006437775\n",
       "[6,] 0.003949782 0.004051825 0.005973617 0.006448189 0.006836812 0.006869952"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "head(cbind(VALUE9[[1]]$f1_79_84$train.y, VALUE9[[1]]$f1_79_84$train.x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training the models\n",
    "We select the sixth station and first fold to illustrate the training process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.x <- VALUE9[[6]]$f1_79_84$train.x\n",
    "train.y <- VALUE9[[6]]$f1_79_84$train.y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The function `randomForestTrain()` builds the model for the predictors `x` and predictands `y`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf <- randomForestTrain(x = train.x, y = train.y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can specify the parameters `mtry`, the number of predictors to randomly use as candidate split variables; `ntree`, the number of trees in the model; `minbucket`, the minimum number of elements each leaf is required to have; `minsplit`, the minimum number of elements each node is required to have to attempt split; and `maxdepth`, the maximum allowed depth for each tree."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf <- randomForestTrain(x = train.x, y = train.y, ntree = 25, mtry = 22, \n",
    "                        minbucket = 10, minsplit = 30, maxdepth = 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By default the models use root mean squared error as split function. The parameter `split.function` allows different split functions, as defined in the modified version of `rpart`. Currently supported options are `\"anova\", \"poisson\", \"class\", \"exp\", \"gammaLLMME\", \"gammaLLmean\", \"bernoulliGammaLLMME\", \"gammaDeviation\", \"gammaLLBC3\", \"bernoulliLL\"`. \n",
    "\n",
    "In this work we restrict ourselves to the gamma 2 parameter distribution family."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf.dev <- randomForestTrain(x = train.x, y = train.y, ntree = 100, minbucket = 10, method = \"gammaDeviation\")\n",
    "rf.LLMME <- randomForestTrain(x = train.x, y = train.y, ntree = 100, minbucket = 10, method = \"gammaLLMME\")\n",
    "rf.LLBC3 <- randomForestTrain(x = train.x, y = train.y, ntree = 100, minbucket = 10, method = \"gammaLLBC3\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parallelization\n",
    "\n",
    "The training process can be parallelized by means of the package `future.apply`. The package has to be installed independently, otherwise parallelization will not be an option. Use `install.packages(future.apply)` to install it. This will also install the dependency `future`.\n",
    "\n",
    "The simplest way to use parallelization is setting `parallel.plan = \"auto\"`. This will automatically use all the available cores to train the model in parallel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf <- randomForestTrain(x = train.x, y = train.y, ntree = 100, minbucket = 10,\n",
    "                        method = \"gammaDeviation\",\n",
    "                        parallel.plan = \"auto\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If not set to `\"auto\"`, the parameter `paralell.plan` corresponds to the execution plan corresponding to the `strategy` parameter in `future::plan()`. Refer to the packages `future` and `future.apply` for the available options. As an example, we show how parallelization in 4 cores can be achieved in combination with the parameter `workers` and setting the `parallel.plan` to `multisession`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf <- randomForestTrain(x = train.x, y = train.y, ntree = 100, minbucket = 10, \n",
    "                        method = \"gammaDeviation\", \n",
    "                        parallel.plan = future::multisession, workers = 4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Also, if left missing or set to `NULL` (default), the function will use the current plan. This is useful for configuration of the plan outside the function, as we do in the next example. We set the execution to `multisession()` prior to launching the loop and train several models using this plan (do not forget to close the sessions by reverting to `sequential()`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "future::plan(future::multisession, workers = 4)\n",
    "\n",
    "rfs <- lapply(VALUE9[[1]], function(fold){\n",
    "    return(\n",
    "        randomForestTrain(x = fold$train.x, y = fold$train.y, ntree = 25, minbucket = 10, \n",
    "                          method = \"gammaDeviation\",\n",
    "                          parallel.plan = NULL)\n",
    "    )\n",
    "    \n",
    "})\n",
    "\n",
    "future::plan(future::sequential)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that using `parallel.plan = NA` will avoid parallelization altogether. This is the default if `future.apply` is not available."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predictions and Simulations\n",
    "\n",
    "Predictions can be obtained using the function `randomForestPredict()`. We use the out-of-sample predictors for the models above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "test.x <- VALUE9[[6]]$f1_79_84$test.x\n",
    "test.y <- VALUE9[[6]]$f1_79_84$test.y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The default configuration uses bagging:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>\n",
       ".dl-inline {width: auto; margin:0; padding: 0}\n",
       ".dl-inline>dt, .dl-inline>dd {float: none; width: auto; display: inline-block}\n",
       ".dl-inline>dt::after {content: \":\\0020\"; padding-right: .5ex}\n",
       ".dl-inline>dt:not(:first-of-type) {padding-left: .5ex}\n",
       "</style><dl class=dl-inline><dt>1</dt><dd>5.9906754434463</dd><dt>2</dt><dd>2.87777896302614</dd><dt>3</dt><dd>4.3545702299936</dd><dt>4</dt><dd>2.23586068353731</dd><dt>5</dt><dd>3.74359326034732</dd><dt>6</dt><dd>9.59665578744871</dd></dl>\n"
      ],
      "text/latex": [
       "\\begin{description*}\n",
       "\\item[1] 5.9906754434463\n",
       "\\item[2] 2.87777896302614\n",
       "\\item[3] 4.3545702299936\n",
       "\\item[4] 2.23586068353731\n",
       "\\item[5] 3.74359326034732\n",
       "\\item[6] 9.59665578744871\n",
       "\\end{description*}\n"
      ],
      "text/markdown": [
       "1\n",
       ":   5.99067544344632\n",
       ":   2.877778963026143\n",
       ":   4.35457022999364\n",
       ":   2.235860683537315\n",
       ":   3.743593260347326\n",
       ":   9.59665578744871\n",
       "\n"
      ],
      "text/plain": [
       "       1        2        3        4        5        6 \n",
       "5.990675 2.877779 4.354570 2.235861 3.743593 9.596656 "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pr <- randomForestPredict(rf, newdata = test.x)\n",
    "head(pr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The parameter `bagging.function` can be used to use other aggregation functions. Also, if set to `NA` the model outputs all the trees' predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<caption>A matrix: 10 × 100 of type dbl</caption>\n",
       "<tbody>\n",
       "\t<tr><th scope=row>1</th><td>28.200000</td><td> 7.4823529</td><td> 3.561111</td><td>18.7100000</td><td> 6.622222</td><td> 5.7600000</td><td>13.550000</td><td> 1.7769231</td><td> 4.420000</td><td> 6.760000</td><td>⋯</td><td> 5.763158</td><td> 6.270000</td><td> 6.3923077</td><td> 2.8812500</td><td> 3.1153846</td><td> 2.978947</td><td>19.366667</td><td> 1.761111</td><td> 6.1266667</td><td>4.2368421</td></tr>\n",
       "\t<tr><th scope=row>2</th><td> 0.990000</td><td> 0.7400000</td><td> 5.480000</td><td> 5.5769231</td><td> 2.440000</td><td> 1.9400000</td><td> 1.994737</td><td> 0.7000000</td><td> 1.681818</td><td> 1.818182</td><td>⋯</td><td> 5.763158</td><td> 1.858824</td><td> 0.9727273</td><td> 0.7789474</td><td> 1.6416667</td><td> 3.238889</td><td> 2.445455</td><td>10.133333</td><td> 4.7500000</td><td>2.6187500</td></tr>\n",
       "\t<tr><th scope=row>3</th><td> 4.346154</td><td> 1.0692308</td><td> 5.480000</td><td> 5.5769231</td><td> 2.440000</td><td> 1.0500000</td><td>13.590000</td><td> 2.4142857</td><td> 4.420000</td><td> 4.326667</td><td>⋯</td><td> 5.763158</td><td> 5.254545</td><td> 3.6000000</td><td> 0.7789474</td><td> 3.1153846</td><td> 5.785714</td><td> 3.535714</td><td>10.133333</td><td> 2.0600000</td><td>7.4357143</td></tr>\n",
       "\t<tr><th scope=row>4</th><td> 1.450000</td><td> 0.7400000</td><td> 1.436364</td><td> 0.5789474</td><td> 2.440000</td><td> 1.0500000</td><td> 1.064706</td><td> 1.7769231</td><td> 1.000000</td><td> 8.725000</td><td>⋯</td><td> 5.763158</td><td> 5.254545</td><td> 2.2846154</td><td> 0.6066667</td><td> 0.4157895</td><td> 2.978947</td><td> 7.011765</td><td> 1.761111</td><td> 0.5181818</td><td>4.7000000</td></tr>\n",
       "\t<tr><th scope=row>5</th><td>10.116667</td><td> 1.6700000</td><td> 3.561111</td><td> 6.4266667</td><td> 1.063636</td><td> 0.9428571</td><td>11.710000</td><td> 0.4466667</td><td> 5.517647</td><td> 1.463158</td><td>⋯</td><td> 3.358333</td><td> 6.723077</td><td>11.4555556</td><td> 5.9300000</td><td> 1.9800000</td><td> 2.269231</td><td> 2.563636</td><td> 7.589474</td><td> 3.6500000</td><td>0.9153846</td></tr>\n",
       "\t<tr><th scope=row>6</th><td> 5.066667</td><td>13.6562500</td><td> 1.607143</td><td> 7.8363636</td><td>11.480000</td><td>13.1454545</td><td> 6.525000</td><td> 4.5388889</td><td>32.305556</td><td> 4.446154</td><td>⋯</td><td> 5.170588</td><td> 5.900000</td><td> 5.3727273</td><td> 6.8100000</td><td> 2.5200000</td><td>12.823077</td><td> 6.864286</td><td>10.850000</td><td> 9.1647059</td><td>8.1769231</td></tr>\n",
       "\t<tr><th scope=row>7</th><td>16.886667</td><td> 3.3916667</td><td> 6.630000</td><td> 9.0833333</td><td>10.600000</td><td> 6.3000000</td><td> 4.670588</td><td>14.2250000</td><td> 5.506250</td><td> 8.945455</td><td>⋯</td><td> 2.190000</td><td> 7.870000</td><td>22.6700000</td><td> 4.9230769</td><td> 5.0294118</td><td>11.028571</td><td> 1.625000</td><td> 8.000000</td><td> 5.4250000</td><td>7.4600000</td></tr>\n",
       "\t<tr><th scope=row>8</th><td> 2.500000</td><td> 0.7058824</td><td> 1.150000</td><td> 8.8272727</td><td> 4.590000</td><td> 4.2235294</td><td> 6.146154</td><td> 8.4500000</td><td> 1.681818</td><td> 4.676923</td><td>⋯</td><td> 3.236364</td><td> 6.108333</td><td> 4.4157895</td><td> 1.3818182</td><td> 7.1181818</td><td> 4.769231</td><td> 1.590000</td><td> 2.520000</td><td> 1.9470588</td><td>5.3818182</td></tr>\n",
       "\t<tr><th scope=row>9</th><td> 6.933333</td><td> 7.1900000</td><td>11.773684</td><td>12.5000000</td><td> 8.887500</td><td> 8.9714286</td><td>12.669231</td><td> 8.2545455</td><td> 9.766667</td><td>10.916667</td><td>⋯</td><td> 5.241667</td><td>13.900000</td><td>17.6250000</td><td>14.5900000</td><td> 7.0454545</td><td> 4.218182</td><td> 8.800000</td><td> 5.670000</td><td> 3.6687500</td><td>8.4187500</td></tr>\n",
       "\t<tr><th scope=row>10</th><td>10.136364</td><td>11.8363636</td><td> 8.740000</td><td>11.5153846</td><td>18.060000</td><td>14.8166667</td><td>13.125000</td><td>15.4153846</td><td> 9.529412</td><td> 6.950000</td><td>⋯</td><td>12.247368</td><td>20.814286</td><td>10.5062500</td><td>11.1928571</td><td>17.4000000</td><td> 5.545455</td><td> 8.310526</td><td> 6.872727</td><td>10.6100000</td><td>8.4187500</td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "A matrix: 10 × 100 of type dbl\n",
       "\\begin{tabular}{r|lllllllllllllllllllll}\n",
       "\t1 & 28.200000 &  7.4823529 &  3.561111 & 18.7100000 &  6.622222 &  5.7600000 & 13.550000 &  1.7769231 &  4.420000 &  6.760000 & ⋯ &  5.763158 &  6.270000 &  6.3923077 &  2.8812500 &  3.1153846 &  2.978947 & 19.366667 &  1.761111 &  6.1266667 & 4.2368421\\\\\n",
       "\t2 &  0.990000 &  0.7400000 &  5.480000 &  5.5769231 &  2.440000 &  1.9400000 &  1.994737 &  0.7000000 &  1.681818 &  1.818182 & ⋯ &  5.763158 &  1.858824 &  0.9727273 &  0.7789474 &  1.6416667 &  3.238889 &  2.445455 & 10.133333 &  4.7500000 & 2.6187500\\\\\n",
       "\t3 &  4.346154 &  1.0692308 &  5.480000 &  5.5769231 &  2.440000 &  1.0500000 & 13.590000 &  2.4142857 &  4.420000 &  4.326667 & ⋯ &  5.763158 &  5.254545 &  3.6000000 &  0.7789474 &  3.1153846 &  5.785714 &  3.535714 & 10.133333 &  2.0600000 & 7.4357143\\\\\n",
       "\t4 &  1.450000 &  0.7400000 &  1.436364 &  0.5789474 &  2.440000 &  1.0500000 &  1.064706 &  1.7769231 &  1.000000 &  8.725000 & ⋯ &  5.763158 &  5.254545 &  2.2846154 &  0.6066667 &  0.4157895 &  2.978947 &  7.011765 &  1.761111 &  0.5181818 & 4.7000000\\\\\n",
       "\t5 & 10.116667 &  1.6700000 &  3.561111 &  6.4266667 &  1.063636 &  0.9428571 & 11.710000 &  0.4466667 &  5.517647 &  1.463158 & ⋯ &  3.358333 &  6.723077 & 11.4555556 &  5.9300000 &  1.9800000 &  2.269231 &  2.563636 &  7.589474 &  3.6500000 & 0.9153846\\\\\n",
       "\t6 &  5.066667 & 13.6562500 &  1.607143 &  7.8363636 & 11.480000 & 13.1454545 &  6.525000 &  4.5388889 & 32.305556 &  4.446154 & ⋯ &  5.170588 &  5.900000 &  5.3727273 &  6.8100000 &  2.5200000 & 12.823077 &  6.864286 & 10.850000 &  9.1647059 & 8.1769231\\\\\n",
       "\t7 & 16.886667 &  3.3916667 &  6.630000 &  9.0833333 & 10.600000 &  6.3000000 &  4.670588 & 14.2250000 &  5.506250 &  8.945455 & ⋯ &  2.190000 &  7.870000 & 22.6700000 &  4.9230769 &  5.0294118 & 11.028571 &  1.625000 &  8.000000 &  5.4250000 & 7.4600000\\\\\n",
       "\t8 &  2.500000 &  0.7058824 &  1.150000 &  8.8272727 &  4.590000 &  4.2235294 &  6.146154 &  8.4500000 &  1.681818 &  4.676923 & ⋯ &  3.236364 &  6.108333 &  4.4157895 &  1.3818182 &  7.1181818 &  4.769231 &  1.590000 &  2.520000 &  1.9470588 & 5.3818182\\\\\n",
       "\t9 &  6.933333 &  7.1900000 & 11.773684 & 12.5000000 &  8.887500 &  8.9714286 & 12.669231 &  8.2545455 &  9.766667 & 10.916667 & ⋯ &  5.241667 & 13.900000 & 17.6250000 & 14.5900000 &  7.0454545 &  4.218182 &  8.800000 &  5.670000 &  3.6687500 & 8.4187500\\\\\n",
       "\t10 & 10.136364 & 11.8363636 &  8.740000 & 11.5153846 & 18.060000 & 14.8166667 & 13.125000 & 15.4153846 &  9.529412 &  6.950000 & ⋯ & 12.247368 & 20.814286 & 10.5062500 & 11.1928571 & 17.4000000 &  5.545455 &  8.310526 &  6.872727 & 10.6100000 & 8.4187500\\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "A matrix: 10 × 100 of type dbl\n",
       "\n",
       "| 1 | 28.200000 |  7.4823529 |  3.561111 | 18.7100000 |  6.622222 |  5.7600000 | 13.550000 |  1.7769231 |  4.420000 |  6.760000 | ⋯ |  5.763158 |  6.270000 |  6.3923077 |  2.8812500 |  3.1153846 |  2.978947 | 19.366667 |  1.761111 |  6.1266667 | 4.2368421 |\n",
       "| 2 |  0.990000 |  0.7400000 |  5.480000 |  5.5769231 |  2.440000 |  1.9400000 |  1.994737 |  0.7000000 |  1.681818 |  1.818182 | ⋯ |  5.763158 |  1.858824 |  0.9727273 |  0.7789474 |  1.6416667 |  3.238889 |  2.445455 | 10.133333 |  4.7500000 | 2.6187500 |\n",
       "| 3 |  4.346154 |  1.0692308 |  5.480000 |  5.5769231 |  2.440000 |  1.0500000 | 13.590000 |  2.4142857 |  4.420000 |  4.326667 | ⋯ |  5.763158 |  5.254545 |  3.6000000 |  0.7789474 |  3.1153846 |  5.785714 |  3.535714 | 10.133333 |  2.0600000 | 7.4357143 |\n",
       "| 4 |  1.450000 |  0.7400000 |  1.436364 |  0.5789474 |  2.440000 |  1.0500000 |  1.064706 |  1.7769231 |  1.000000 |  8.725000 | ⋯ |  5.763158 |  5.254545 |  2.2846154 |  0.6066667 |  0.4157895 |  2.978947 |  7.011765 |  1.761111 |  0.5181818 | 4.7000000 |\n",
       "| 5 | 10.116667 |  1.6700000 |  3.561111 |  6.4266667 |  1.063636 |  0.9428571 | 11.710000 |  0.4466667 |  5.517647 |  1.463158 | ⋯ |  3.358333 |  6.723077 | 11.4555556 |  5.9300000 |  1.9800000 |  2.269231 |  2.563636 |  7.589474 |  3.6500000 | 0.9153846 |\n",
       "| 6 |  5.066667 | 13.6562500 |  1.607143 |  7.8363636 | 11.480000 | 13.1454545 |  6.525000 |  4.5388889 | 32.305556 |  4.446154 | ⋯ |  5.170588 |  5.900000 |  5.3727273 |  6.8100000 |  2.5200000 | 12.823077 |  6.864286 | 10.850000 |  9.1647059 | 8.1769231 |\n",
       "| 7 | 16.886667 |  3.3916667 |  6.630000 |  9.0833333 | 10.600000 |  6.3000000 |  4.670588 | 14.2250000 |  5.506250 |  8.945455 | ⋯ |  2.190000 |  7.870000 | 22.6700000 |  4.9230769 |  5.0294118 | 11.028571 |  1.625000 |  8.000000 |  5.4250000 | 7.4600000 |\n",
       "| 8 |  2.500000 |  0.7058824 |  1.150000 |  8.8272727 |  4.590000 |  4.2235294 |  6.146154 |  8.4500000 |  1.681818 |  4.676923 | ⋯ |  3.236364 |  6.108333 |  4.4157895 |  1.3818182 |  7.1181818 |  4.769231 |  1.590000 |  2.520000 |  1.9470588 | 5.3818182 |\n",
       "| 9 |  6.933333 |  7.1900000 | 11.773684 | 12.5000000 |  8.887500 |  8.9714286 | 12.669231 |  8.2545455 |  9.766667 | 10.916667 | ⋯ |  5.241667 | 13.900000 | 17.6250000 | 14.5900000 |  7.0454545 |  4.218182 |  8.800000 |  5.670000 |  3.6687500 | 8.4187500 |\n",
       "| 10 | 10.136364 | 11.8363636 |  8.740000 | 11.5153846 | 18.060000 | 14.8166667 | 13.125000 | 15.4153846 |  9.529412 |  6.950000 | ⋯ | 12.247368 | 20.814286 | 10.5062500 | 11.1928571 | 17.4000000 |  5.545455 |  8.310526 |  6.872727 | 10.6100000 | 8.4187500 |\n",
       "\n"
      ],
      "text/plain": [
       "   [,1]      [,2]       [,3]      [,4]       [,5]      [,6]       [,7]     \n",
       "1  28.200000  7.4823529  3.561111 18.7100000  6.622222  5.7600000 13.550000\n",
       "2   0.990000  0.7400000  5.480000  5.5769231  2.440000  1.9400000  1.994737\n",
       "3   4.346154  1.0692308  5.480000  5.5769231  2.440000  1.0500000 13.590000\n",
       "4   1.450000  0.7400000  1.436364  0.5789474  2.440000  1.0500000  1.064706\n",
       "5  10.116667  1.6700000  3.561111  6.4266667  1.063636  0.9428571 11.710000\n",
       "6   5.066667 13.6562500  1.607143  7.8363636 11.480000 13.1454545  6.525000\n",
       "7  16.886667  3.3916667  6.630000  9.0833333 10.600000  6.3000000  4.670588\n",
       "8   2.500000  0.7058824  1.150000  8.8272727  4.590000  4.2235294  6.146154\n",
       "9   6.933333  7.1900000 11.773684 12.5000000  8.887500  8.9714286 12.669231\n",
       "10 10.136364 11.8363636  8.740000 11.5153846 18.060000 14.8166667 13.125000\n",
       "   [,8]       [,9]      [,10]     [,11] [,12]     [,13]     [,14]     \n",
       "1   1.7769231  4.420000  6.760000 ⋯      5.763158  6.270000  6.3923077\n",
       "2   0.7000000  1.681818  1.818182 ⋯      5.763158  1.858824  0.9727273\n",
       "3   2.4142857  4.420000  4.326667 ⋯      5.763158  5.254545  3.6000000\n",
       "4   1.7769231  1.000000  8.725000 ⋯      5.763158  5.254545  2.2846154\n",
       "5   0.4466667  5.517647  1.463158 ⋯      3.358333  6.723077 11.4555556\n",
       "6   4.5388889 32.305556  4.446154 ⋯      5.170588  5.900000  5.3727273\n",
       "7  14.2250000  5.506250  8.945455 ⋯      2.190000  7.870000 22.6700000\n",
       "8   8.4500000  1.681818  4.676923 ⋯      3.236364  6.108333  4.4157895\n",
       "9   8.2545455  9.766667 10.916667 ⋯      5.241667 13.900000 17.6250000\n",
       "10 15.4153846  9.529412  6.950000 ⋯     12.247368 20.814286 10.5062500\n",
       "   [,15]      [,16]      [,17]     [,18]     [,19]     [,20]      [,21]    \n",
       "1   2.8812500  3.1153846  2.978947 19.366667  1.761111  6.1266667 4.2368421\n",
       "2   0.7789474  1.6416667  3.238889  2.445455 10.133333  4.7500000 2.6187500\n",
       "3   0.7789474  3.1153846  5.785714  3.535714 10.133333  2.0600000 7.4357143\n",
       "4   0.6066667  0.4157895  2.978947  7.011765  1.761111  0.5181818 4.7000000\n",
       "5   5.9300000  1.9800000  2.269231  2.563636  7.589474  3.6500000 0.9153846\n",
       "6   6.8100000  2.5200000 12.823077  6.864286 10.850000  9.1647059 8.1769231\n",
       "7   4.9230769  5.0294118 11.028571  1.625000  8.000000  5.4250000 7.4600000\n",
       "8   1.3818182  7.1181818  4.769231  1.590000  2.520000  1.9470588 5.3818182\n",
       "9  14.5900000  7.0454545  4.218182  8.800000  5.670000  3.6687500 8.4187500\n",
       "10 11.1928571 17.4000000  5.545455  8.310526  6.872727 10.6100000 8.4187500"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pr.median <- randomForestPredict(rf, newdata = test.x, bagging.function = median)\n",
    "pr.alltrees <- randomForestPredict(rf, newdata = test.x, bagging.function = NA)\n",
    "pr.alltrees[1:10,] # Show the output of all the trees for the first 10 days"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The parameter `method` controls the *a posteriori* approaches (described in the article). The options are described in the help page (`?randomForestPredict`), and we summarize them here. If `method` is not `NULL`, `bagging.function` is ignored.\n",
    "\n",
    "- `method = \"leaves\"` outputs all the observations for each predictor. \n",
    "- `method = \"random.sample\"` draws a random sample from the leaves for each predictor. This approach is non-generative.\n",
    "- `method = \"aposteriori\"` returns the parameter of the probability distribution of `train.y | train.x`, as estimated using Moments Matching Estimation (refer to `fitdistrplus::fitdist()`). In the case of the gamma distribution, this outputs the shape and rate of the distribution.\n",
    "- Additionally, this parameter can be used to select the estimation method for fitdistrplus::fitdist(), i.e. one of the following: `\"mle\"` for Maximum Likelihood Estimation; `\"mme\"` for Moments Matching Estimation (same as `\"aposteriori\"`); `\"qme\"` for Quantile Matching Estimation; `\"mge\"` for Maximum Goodness-of-fit Estimation; \"`mse`\" for Maximum Spacing Estimation. Note that some of these options require additional parameters (use `...`), and that some of them may not converge.\n",
    "\n",
    "We provide some examples below.\n",
    "\n",
    "Predicting the leaves observations allows us to plot `train.y | train.x`. We do this for two values:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA0gAAANICAIAAAByhViMAAAACXBIWXMAABJ0AAASdAHeZh94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\nADpBYwcAAKAT/w9/oLggOgYPQwAAAABJRU5ErkJggg==",
      "text/plain": [
       "Plot with title “test.y | train.x”"
      ]
     },
     "metadata": {
      "image/png": {
       "height": 420,
       "width": 420
      },
      "text/plain": {
       "height": 420,
       "width": 420
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "pr.leaves <- randomForestPredict(rf, newdata = test.x, method = \"leaves\")\n",
    "\n",
    "par(mfrow = c(1,2))\n",
    "hist(pr.leaves[[100]], breaks = 50, xlab = \"Rainfall\", freq = FALSE,\n",
    "     main = \"test.y | train.x\", ylim = c(0, 0.25), xlim = c(0,60))\n",
    "hist(pr.leaves[[300]], breaks = 50, xlab = \"Rainfall\", freq = FALSE, \n",
    "     main = \"test.y | train.x\",ylim = c(0, 0.25), xlim = c(0,60))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As the model was trained using the deviation for the two-parameter gamma distribution, using `method = \"aposteriori\"` outputs the two parameter for each prediction:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<caption>A matrix: 10 × 2 of type dbl</caption>\n",
       "<thead>\n",
       "\t<tr><th scope=col>shape</th><th scope=col>rate</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "\t<tr><td>0.6631633</td><td>0.1139398</td></tr>\n",
       "\t<tr><td>0.8268574</td><td>0.2863083</td></tr>\n",
       "\t<tr><td>1.3305145</td><td>0.3068724</td></tr>\n",
       "\t<tr><td>0.7090563</td><td>0.3123169</td></tr>\n",
       "\t<tr><td>1.0520843</td><td>0.2755289</td></tr>\n",
       "\t<tr><td>1.1618595</td><td>0.1227533</td></tr>\n",
       "\t<tr><td>1.5472187</td><td>0.1829556</td></tr>\n",
       "\t<tr><td>1.0002698</td><td>0.2409027</td></tr>\n",
       "\t<tr><td>2.5591922</td><td>0.2631880</td></tr>\n",
       "\t<tr><td>4.3655413</td><td>0.3587182</td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "A matrix: 10 × 2 of type dbl\n",
       "\\begin{tabular}{ll}\n",
       " shape & rate\\\\\n",
       "\\hline\n",
       "\t 0.6631633 & 0.1139398\\\\\n",
       "\t 0.8268574 & 0.2863083\\\\\n",
       "\t 1.3305145 & 0.3068724\\\\\n",
       "\t 0.7090563 & 0.3123169\\\\\n",
       "\t 1.0520843 & 0.2755289\\\\\n",
       "\t 1.1618595 & 0.1227533\\\\\n",
       "\t 1.5472187 & 0.1829556\\\\\n",
       "\t 1.0002698 & 0.2409027\\\\\n",
       "\t 2.5591922 & 0.2631880\\\\\n",
       "\t 4.3655413 & 0.3587182\\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "A matrix: 10 × 2 of type dbl\n",
       "\n",
       "| shape | rate |\n",
       "|---|---|\n",
       "| 0.6631633 | 0.1139398 |\n",
       "| 0.8268574 | 0.2863083 |\n",
       "| 1.3305145 | 0.3068724 |\n",
       "| 0.7090563 | 0.3123169 |\n",
       "| 1.0520843 | 0.2755289 |\n",
       "| 1.1618595 | 0.1227533 |\n",
       "| 1.5472187 | 0.1829556 |\n",
       "| 1.0002698 | 0.2409027 |\n",
       "| 2.5591922 | 0.2631880 |\n",
       "| 4.3655413 | 0.3587182 |\n",
       "\n"
      ],
      "text/plain": [
       "      shape     rate     \n",
       " [1,] 0.6631633 0.1139398\n",
       " [2,] 0.8268574 0.2863083\n",
       " [3,] 1.3305145 0.3068724\n",
       " [4,] 0.7090563 0.3123169\n",
       " [5,] 1.0520843 0.2755289\n",
       " [6,] 1.1618595 0.1227533\n",
       " [7,] 1.5472187 0.1829556\n",
       " [8,] 1.0002698 0.2409027\n",
       " [9,] 2.5591922 0.2631880\n",
       "[10,] 4.3655413 0.3587182"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pr.distr <- randomForestPredict(rf, newdata = test.x, method = \"aposteriori\")\n",
    "pr.distr[1:10,] # We show the first 10 days"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As stated above, we can also directly input the method to `fitdistrplus::fitdist()`. For instance, we use maximum likelihood estimation with `method = \"mle\"`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<caption>A matrix: 10 × 2 of type dbl</caption>\n",
       "<thead>\n",
       "\t<tr><th scope=col>shape</th><th scope=col>rate</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "\t<tr><td>0.6631633</td><td>0.1139398</td></tr>\n",
       "\t<tr><td>0.8268574</td><td>0.2863083</td></tr>\n",
       "\t<tr><td>1.3305145</td><td>0.3068724</td></tr>\n",
       "\t<tr><td>0.7090563</td><td>0.3123169</td></tr>\n",
       "\t<tr><td>1.0520843</td><td>0.2755289</td></tr>\n",
       "\t<tr><td>1.1618595</td><td>0.1227533</td></tr>\n",
       "\t<tr><td>1.5472187</td><td>0.1829556</td></tr>\n",
       "\t<tr><td>1.0002698</td><td>0.2409027</td></tr>\n",
       "\t<tr><td>2.5591922</td><td>0.2631880</td></tr>\n",
       "\t<tr><td>4.3655413</td><td>0.3587182</td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "A matrix: 10 × 2 of type dbl\n",
       "\\begin{tabular}{ll}\n",
       " shape & rate\\\\\n",
       "\\hline\n",
       "\t 0.6631633 & 0.1139398\\\\\n",
       "\t 0.8268574 & 0.2863083\\\\\n",
       "\t 1.3305145 & 0.3068724\\\\\n",
       "\t 0.7090563 & 0.3123169\\\\\n",
       "\t 1.0520843 & 0.2755289\\\\\n",
       "\t 1.1618595 & 0.1227533\\\\\n",
       "\t 1.5472187 & 0.1829556\\\\\n",
       "\t 1.0002698 & 0.2409027\\\\\n",
       "\t 2.5591922 & 0.2631880\\\\\n",
       "\t 4.3655413 & 0.3587182\\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "A matrix: 10 × 2 of type dbl\n",
       "\n",
       "| shape | rate |\n",
       "|---|---|\n",
       "| 0.6631633 | 0.1139398 |\n",
       "| 0.8268574 | 0.2863083 |\n",
       "| 1.3305145 | 0.3068724 |\n",
       "| 0.7090563 | 0.3123169 |\n",
       "| 1.0520843 | 0.2755289 |\n",
       "| 1.1618595 | 0.1227533 |\n",
       "| 1.5472187 | 0.1829556 |\n",
       "| 1.0002698 | 0.2409027 |\n",
       "| 2.5591922 | 0.2631880 |\n",
       "| 4.3655413 | 0.3587182 |\n",
       "\n"
      ],
      "text/plain": [
       "      shape     rate     \n",
       " [1,] 0.6631633 0.1139398\n",
       " [2,] 0.8268574 0.2863083\n",
       " [3,] 1.3305145 0.3068724\n",
       " [4,] 0.7090563 0.3123169\n",
       " [5,] 1.0520843 0.2755289\n",
       " [6,] 1.1618595 0.1227533\n",
       " [7,] 1.5472187 0.1829556\n",
       " [8,] 1.0002698 0.2409027\n",
       " [9,] 2.5591922 0.2631880\n",
       "[10,] 4.3655413 0.3587182"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pr.mle <- randomForestPredict(rf, newdata = test.x, method = \"mle\")\n",
    "pr.distr[1:10,] # Show the predicted distribution for the first 10 days"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we can use the predicted distribution parameters to simulate series. We can do this using the function `randomForestSimulate()`. It takes a prediction object `prediction`, as output by `randomForestPredict()`; and the number of simulated series, `n`. The parameter `distr` allows for manually selecting the distribution, although the distribution will be automatically selected depending on the training split function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "simulation <- randomForestSimulate(pr.distr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We simulate 1000 series:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<caption>A matrix: 6 × 1000 of type dbl</caption>\n",
       "<tbody>\n",
       "\t<tr><td>16.401212</td><td>6.5780394</td><td>24.343978</td><td> 4.3412076</td><td>0.07139387</td><td>3.6298965</td><td> 0.4185125</td><td>3.363125973</td><td> 0.2139395</td><td>0.005142123</td><td>⋯</td><td> 0.9346878</td><td> 5.705862</td><td>11.388554</td><td>4.5430340</td><td> 4.8419281</td><td> 0.06258068</td><td>3.1084244</td><td>7.9085157</td><td>5.4060905</td><td>9.9245108</td></tr>\n",
       "\t<tr><td> 1.824670</td><td>3.7815555</td><td> 2.084874</td><td> 3.3502654</td><td>1.18413629</td><td>5.5643711</td><td> 5.2767448</td><td>0.001689017</td><td> 1.8713019</td><td>0.272114207</td><td>⋯</td><td> 0.5658543</td><td> 0.269166</td><td> 2.132391</td><td>0.7793248</td><td> 1.1089032</td><td> 0.90537817</td><td>0.9458167</td><td>0.9338746</td><td>0.7240090</td><td>0.7232405</td></tr>\n",
       "\t<tr><td> 3.427660</td><td>2.6542311</td><td> 3.191854</td><td> 0.7604726</td><td>2.67361941</td><td>1.2311706</td><td> 0.7198240</td><td>1.637002697</td><td> 0.6421465</td><td>1.613908754</td><td>⋯</td><td> 3.2865840</td><td>11.630846</td><td> 7.312694</td><td>3.2385869</td><td> 6.3071792</td><td> 3.53707248</td><td>0.7251712</td><td>6.4136084</td><td>4.5818876</td><td>7.0369741</td></tr>\n",
       "\t<tr><td>19.928436</td><td>1.0209804</td><td> 5.252162</td><td> 1.1224609</td><td>0.53436078</td><td>0.6001669</td><td> 2.5990611</td><td>3.045652762</td><td> 1.8947598</td><td>1.772928534</td><td>⋯</td><td> 0.1276340</td><td> 2.722498</td><td> 1.866763</td><td>0.2010061</td><td> 3.2361187</td><td> 1.09231113</td><td>1.3175135</td><td>8.4307085</td><td>0.5967682</td><td>0.2733909</td></tr>\n",
       "\t<tr><td> 2.086507</td><td>0.6370393</td><td> 1.705948</td><td>13.7368541</td><td>3.74952797</td><td>0.3958324</td><td> 2.4469552</td><td>4.382129599</td><td> 5.7181549</td><td>1.108579954</td><td>⋯</td><td> 2.5364276</td><td> 4.278047</td><td> 6.086361</td><td>1.3562598</td><td> 0.7429805</td><td>10.48820494</td><td>0.3652106</td><td>8.4044147</td><td>4.9165105</td><td>0.1591949</td></tr>\n",
       "\t<tr><td> 6.042927</td><td>7.3132642</td><td>18.009456</td><td> 7.8590195</td><td>1.14625264</td><td>8.6012624</td><td>17.7699422</td><td>9.408703483</td><td>11.1084704</td><td>0.589946095</td><td>⋯</td><td>10.1754256</td><td> 8.053134</td><td> 1.154221</td><td>7.9929981</td><td>27.4465627</td><td> 5.68099604</td><td>5.4941933</td><td>3.1568796</td><td>5.8866068</td><td>3.5142137</td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "A matrix: 6 × 1000 of type dbl\n",
       "\\begin{tabular}{lllllllllllllllllllll}\n",
       "\t 16.401212 & 6.5780394 & 24.343978 &  4.3412076 & 0.07139387 & 3.6298965 &  0.4185125 & 3.363125973 &  0.2139395 & 0.005142123 & ⋯ &  0.9346878 &  5.705862 & 11.388554 & 4.5430340 &  4.8419281 &  0.06258068 & 3.1084244 & 7.9085157 & 5.4060905 & 9.9245108\\\\\n",
       "\t  1.824670 & 3.7815555 &  2.084874 &  3.3502654 & 1.18413629 & 5.5643711 &  5.2767448 & 0.001689017 &  1.8713019 & 0.272114207 & ⋯ &  0.5658543 &  0.269166 &  2.132391 & 0.7793248 &  1.1089032 &  0.90537817 & 0.9458167 & 0.9338746 & 0.7240090 & 0.7232405\\\\\n",
       "\t  3.427660 & 2.6542311 &  3.191854 &  0.7604726 & 2.67361941 & 1.2311706 &  0.7198240 & 1.637002697 &  0.6421465 & 1.613908754 & ⋯ &  3.2865840 & 11.630846 &  7.312694 & 3.2385869 &  6.3071792 &  3.53707248 & 0.7251712 & 6.4136084 & 4.5818876 & 7.0369741\\\\\n",
       "\t 19.928436 & 1.0209804 &  5.252162 &  1.1224609 & 0.53436078 & 0.6001669 &  2.5990611 & 3.045652762 &  1.8947598 & 1.772928534 & ⋯ &  0.1276340 &  2.722498 &  1.866763 & 0.2010061 &  3.2361187 &  1.09231113 & 1.3175135 & 8.4307085 & 0.5967682 & 0.2733909\\\\\n",
       "\t  2.086507 & 0.6370393 &  1.705948 & 13.7368541 & 3.74952797 & 0.3958324 &  2.4469552 & 4.382129599 &  5.7181549 & 1.108579954 & ⋯ &  2.5364276 &  4.278047 &  6.086361 & 1.3562598 &  0.7429805 & 10.48820494 & 0.3652106 & 8.4044147 & 4.9165105 & 0.1591949\\\\\n",
       "\t  6.042927 & 7.3132642 & 18.009456 &  7.8590195 & 1.14625264 & 8.6012624 & 17.7699422 & 9.408703483 & 11.1084704 & 0.589946095 & ⋯ & 10.1754256 &  8.053134 &  1.154221 & 7.9929981 & 27.4465627 &  5.68099604 & 5.4941933 & 3.1568796 & 5.8866068 & 3.5142137\\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "A matrix: 6 × 1000 of type dbl\n",
       "\n",
       "| 16.401212 | 6.5780394 | 24.343978 |  4.3412076 | 0.07139387 | 3.6298965 |  0.4185125 | 3.363125973 |  0.2139395 | 0.005142123 | ⋯ |  0.9346878 |  5.705862 | 11.388554 | 4.5430340 |  4.8419281 |  0.06258068 | 3.1084244 | 7.9085157 | 5.4060905 | 9.9245108 |\n",
       "|  1.824670 | 3.7815555 |  2.084874 |  3.3502654 | 1.18413629 | 5.5643711 |  5.2767448 | 0.001689017 |  1.8713019 | 0.272114207 | ⋯ |  0.5658543 |  0.269166 |  2.132391 | 0.7793248 |  1.1089032 |  0.90537817 | 0.9458167 | 0.9338746 | 0.7240090 | 0.7232405 |\n",
       "|  3.427660 | 2.6542311 |  3.191854 |  0.7604726 | 2.67361941 | 1.2311706 |  0.7198240 | 1.637002697 |  0.6421465 | 1.613908754 | ⋯ |  3.2865840 | 11.630846 |  7.312694 | 3.2385869 |  6.3071792 |  3.53707248 | 0.7251712 | 6.4136084 | 4.5818876 | 7.0369741 |\n",
       "| 19.928436 | 1.0209804 |  5.252162 |  1.1224609 | 0.53436078 | 0.6001669 |  2.5990611 | 3.045652762 |  1.8947598 | 1.772928534 | ⋯ |  0.1276340 |  2.722498 |  1.866763 | 0.2010061 |  3.2361187 |  1.09231113 | 1.3175135 | 8.4307085 | 0.5967682 | 0.2733909 |\n",
       "|  2.086507 | 0.6370393 |  1.705948 | 13.7368541 | 3.74952797 | 0.3958324 |  2.4469552 | 4.382129599 |  5.7181549 | 1.108579954 | ⋯ |  2.5364276 |  4.278047 |  6.086361 | 1.3562598 |  0.7429805 | 10.48820494 | 0.3652106 | 8.4044147 | 4.9165105 | 0.1591949 |\n",
       "|  6.042927 | 7.3132642 | 18.009456 |  7.8590195 | 1.14625264 | 8.6012624 | 17.7699422 | 9.408703483 | 11.1084704 | 0.589946095 | ⋯ | 10.1754256 |  8.053134 |  1.154221 | 7.9929981 | 27.4465627 |  5.68099604 | 5.4941933 | 3.1568796 | 5.8866068 | 3.5142137 |\n",
       "\n"
      ],
      "text/plain": [
       "     [,1]      [,2]      [,3]      [,4]       [,5]       [,6]      [,7]      \n",
       "[1,] 16.401212 6.5780394 24.343978  4.3412076 0.07139387 3.6298965  0.4185125\n",
       "[2,]  1.824670 3.7815555  2.084874  3.3502654 1.18413629 5.5643711  5.2767448\n",
       "[3,]  3.427660 2.6542311  3.191854  0.7604726 2.67361941 1.2311706  0.7198240\n",
       "[4,] 19.928436 1.0209804  5.252162  1.1224609 0.53436078 0.6001669  2.5990611\n",
       "[5,]  2.086507 0.6370393  1.705948 13.7368541 3.74952797 0.3958324  2.4469552\n",
       "[6,]  6.042927 7.3132642 18.009456  7.8590195 1.14625264 8.6012624 17.7699422\n",
       "     [,8]        [,9]       [,10]       [,11] [,12]      [,13]     [,14]    \n",
       "[1,] 3.363125973  0.2139395 0.005142123 ⋯      0.9346878  5.705862 11.388554\n",
       "[2,] 0.001689017  1.8713019 0.272114207 ⋯      0.5658543  0.269166  2.132391\n",
       "[3,] 1.637002697  0.6421465 1.613908754 ⋯      3.2865840 11.630846  7.312694\n",
       "[4,] 3.045652762  1.8947598 1.772928534 ⋯      0.1276340  2.722498  1.866763\n",
       "[5,] 4.382129599  5.7181549 1.108579954 ⋯      2.5364276  4.278047  6.086361\n",
       "[6,] 9.408703483 11.1084704 0.589946095 ⋯     10.1754256  8.053134  1.154221\n",
       "     [,15]     [,16]      [,17]       [,18]     [,19]     [,20]     [,21]    \n",
       "[1,] 4.5430340  4.8419281  0.06258068 3.1084244 7.9085157 5.4060905 9.9245108\n",
       "[2,] 0.7793248  1.1089032  0.90537817 0.9458167 0.9338746 0.7240090 0.7232405\n",
       "[3,] 3.2385869  6.3071792  3.53707248 0.7251712 6.4136084 4.5818876 7.0369741\n",
       "[4,] 0.2010061  3.2361187  1.09231113 1.3175135 8.4307085 0.5967682 0.2733909\n",
       "[5,] 1.3562598  0.7429805 10.48820494 0.3652106 8.4044147 4.9165105 0.1591949\n",
       "[6,] 7.9929981 27.4465627  5.68099604 5.4941933 3.1568796 5.8866068 3.5142137"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "simulations <- randomForestSimulate(pr.distr, n = 1000)\n",
    "head(simulations)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Complete Example\n",
    "\n",
    "Finally, we reproduce here the 5-Fold experiment described in the article *Stochastic Downscaling of Precipitation using Random Forests* for the set of 9 stations. We use a model with $25$ trees, minimum leaf size $5$ and Deviation as split function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "future::plan(future::multisession, workers = 6)\n",
    "\n",
    "predictions <-\n",
    "lapply(VALUE9, function(meteorological.station){\n",
    "    predictions <- lapply(meteorological.station, function(fold){\n",
    "        md <- randomForestTrain(x = fold$train.x, y = fold$train.y, \n",
    "                                ntree = 25, minbucket = 5, \n",
    "                                method = \"gammaDeviation\",\n",
    "                                parallel.plan = NULL)\n",
    "        \n",
    "        return( list(predicted = randomForestPredict(md, newdata = fold$test.x, method = \"mme\"),\n",
    "                     observed = fold$test.y)\n",
    "              )\n",
    "    })\n",
    "    \n",
    "    predicted <- do.call(rbind, lapply(predictions, function(pr) pr$predicted))\n",
    "    observed <- do.call(c, lapply(predictions, function(pr) pr$observed))\n",
    "\n",
    "    return( list(predicted = predicted, observed = observed) )\n",
    "})\n",
    "\n",
    "future::plan(future::sequential)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We end up with the downscaled probability distribution for each station and day."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
